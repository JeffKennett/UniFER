# UniFER ä½¿ç”¨æ–‡æ¡£

æœ¬æ–‡æ¡£æä¾›UniFERé¡¹ç›®çš„è¯¦ç»†ä½¿ç”¨è¯´æ˜ï¼ŒåŒ…æ‹¬ç¯å¢ƒé…ç½®ã€æ•°æ®å‡†å¤‡ã€æ¨¡å‹è®­ç»ƒã€æ¨ç†è¯„ä¼°ç­‰å®Œæ•´æµç¨‹ã€‚

---

## ğŸ“¦ ä¸€ã€ç¯å¢ƒé…ç½®

### 1.1 ç³»ç»Ÿè¦æ±‚

- **æ“ä½œç³»ç»Ÿ**: Linux (æ¨è Ubuntu 20.04+)
- **Pythonç‰ˆæœ¬**: 3.11
- **CUDAç‰ˆæœ¬**: 11.8+ (æ”¯æŒCUDA 12.x)
- **GPUè¦æ±‚**: 
  - æ¨ç†: è‡³å°‘1å¼ 24GBæ˜¾å­˜çš„GPU (å¦‚RTX 3090, RTX 4090, A100)
  - è®­ç»ƒSFT: 4å¼ 24GB+ GPU
  - è®­ç»ƒGRPO: 8å¼ 40GB+ GPU (æ¨èA100)

### 1.2 åˆ›å»ºCondaç¯å¢ƒ

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/zfkarl/UniFER.git
cd UniFER

# åˆ›å»ºcondaç¯å¢ƒ
conda create -n r1-v python=3.11
conda activate r1-v
```

### 1.3 å®‰è£…ä¾èµ–

æŒ‰ç…§R1-Vå®˜æ–¹æ–‡æ¡£å®‰è£…ä¾èµ–ï¼š

```bash
# å®‰è£…PyTorch (æ ¹æ®CUDAç‰ˆæœ¬é€‰æ‹©)
# CUDA 11.8ç¤ºä¾‹
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# å®‰è£…Transformerså’Œç›¸å…³åº“
pip install transformers accelerate peft trl datasets

# å®‰è£…DeepSpeed
pip install deepspeed

# å®‰è£…vLLM (ç”¨äºGRPOåŠ é€Ÿ)
pip install vllm

# å®‰è£…è¯„ä¼°ä¾èµ–
pip install scikit-learn pandas tqdm

# å®‰è£…Qwen-VLå·¥å…·
pip install qwen-vl-utils

# å®‰è£…å…¶ä»–ä¾èµ–
pip install wandb pillow
```

### 1.4 éªŒè¯å®‰è£…

```bash
# éªŒè¯PyTorchå’ŒCUDA
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA: {torch.cuda.is_available()}')"

# éªŒè¯Transformers
python -c "import transformers; print(f'Transformers: {transformers.__version__}')"

# éªŒè¯DeepSpeed
ds_report
```

---

## ğŸ“‚ äºŒã€æ•°æ®å‡†å¤‡

### 2.1 ä¸‹è½½æ•°æ®é›†

#### 2.1.1 è¯„ä¼°æ•°æ®é›†ï¼ˆå›¾åƒï¼‰

ä»å®˜æ–¹ç½‘ç«™ä¸‹è½½ä»¥ä¸‹æ•°æ®é›†çš„å›¾åƒæ–‡ä»¶ï¼š

1. **RAF-DB**
   - ç½‘ç«™: http://www.whdeng.cn/RAF/model1.html
   - ä¸‹è½½: `aligned` æ–‡ä»¶å¤¹
   - æ”¾ç½®è·¯å¾„: `/RAF-DB/aligned/`

2. **FERPlus**
   - ç½‘ç«™: https://github.com/microsoft/FERPlus
   - ä¸‹è½½åŸå§‹FER2013å›¾åƒå¹¶ä½¿ç”¨FERPlusæ ‡ç­¾
   - æ”¾ç½®è·¯å¾„: `/FERPlus/Images/`

3. **AffectNet**
   - ç½‘ç«™: http://mohammadmahoor.com/affectnet/
   - éœ€è¦ç”³è¯·è®¿é—®æƒé™
   - æ”¾ç½®è·¯å¾„: `/AffectNet/`

4. **SFEW 2.0**
   - ç½‘ç«™: https://cs.anu.edu.au/few/AFEW.html
   - ä¸‹è½½SFEW 2.0æ•°æ®é›†
   - æ”¾ç½®è·¯å¾„: `/SFEW_2.0/`

#### 2.1.2 è®­ç»ƒæ•°æ®é›†

ä»Hugging Faceä¸‹è½½UniFERæ•°æ®é›†ï¼š

```bash
# æ–¹æ³•1: ä½¿ç”¨git
cd data/
git lfs install
git clone https://huggingface.co/datasets/Karl28/UniFER

# æ–¹æ³•2: ä½¿ç”¨huggingface-cli
pip install huggingface_hub
huggingface-cli download Karl28/UniFER --local-dir ./data/

# ç¡®ä¿ä»¥ä¸‹æ–‡ä»¶å­˜åœ¨:
# - data/UniFER_CoT_230K.json
# - data/UniFER_RLVR_360K.json
```

### 2.2 æ•°æ®é›†ç»“æ„

ç¡®ä¿æ•°æ®ç›®å½•ç»“æ„å¦‚ä¸‹ï¼š

```
UniFER/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ UniFER_CoT_230K.json      # SFTè®­ç»ƒæ•°æ®
â”‚   â””â”€â”€ UniFER_RLVR_360K.json     # GRPOè®­ç»ƒæ•°æ®
â”œâ”€â”€ eval_rafdb/data/
â”‚   â””â”€â”€ rafdb_qa.json              # RAF-DBæµ‹è¯•é›†
â”œâ”€â”€ eval_ferplus/data/
â”‚   â””â”€â”€ ferplus_qa.json            # FERPlusæµ‹è¯•é›†
â”œâ”€â”€ eval_affectnet/data/
â”‚   â””â”€â”€ affectnet_qa.json          # AffectNetæµ‹è¯•é›†
â””â”€â”€ eval_sfew_2.0/data/
    â””â”€â”€ sfew_2.0_qa.json           # SFEWæµ‹è¯•é›†
```

### 2.3 ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹

#### åŸºç¡€æ¨¡å‹ï¼ˆç”¨äºè®­ç»ƒï¼‰

```bash
# ä¸‹è½½Qwen2.5-VL-7B-Instruct
cd model/
git lfs install
git clone https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct
```

#### å·²è®­ç»ƒæ¨¡å‹ï¼ˆç›´æ¥æ¨ç†ï¼‰

```bash
# ä¸‹è½½UniFER-7B
cd model/
git clone https://huggingface.co/Karl28/UniFER-7B
```

---

## ğŸš€ ä¸‰ã€æ¨¡å‹è®­ç»ƒ

### 3.1 ç¬¬ä¸€é˜¶æ®µï¼šç›‘ç£å¾®è°ƒ (SFT)

#### 3.1.1 å‡†å¤‡é…ç½®

ç¼–è¾‘è®­ç»ƒè„šæœ¬ `train_unifer/src/scripts/run_sft_fer.sh`:

```bash
#!/bin/bash

cd ./UniFER/train_unifer/src/r1-v

# è°ƒè¯•æ¨¡å¼ï¼ˆå¯é€‰ï¼‰
export DEBUG_MODE="true"
export LOG_PATH="./debug_log_sft.txt"

# æ¿€æ´»ç¯å¢ƒ
source /miniconda3/bin/activate
conda activate r1-v

# è®­ç»ƒå‚æ•°
CUDA_VISIBLE_DEVICES=0,1,2,3 torchrun --nproc_per_node="4" \
    --nnodes="1" \
    --node_rank="0" \
    --master_addr="127.0.0.1" \
    --master_port="12349" \
    src/open_r1/sft_fer.py \
    --output_dir "./UniFER/model/Qwen2.5-VL-7B-FER-COT-SFT-230K" \
    --model_name_or_path "./UniFER/model/Qwen2.5-VL-7B-Instruct" \
    --dataset_name "./UniFER/data/UniFER_CoT_230K.json" \
    --deepspeed local_scripts/zero2.json \
    --per_device_train_batch_size 1 \
    --gradient_accumulation_steps 4 \
    --lr_scheduler_type "cosine" \
    --logging_steps 20 \
    --bf16 True \
    --report_to wandb \
    --gradient_checkpointing true \
    --attn_implementation flash_attention_2 \
    --num_train_epochs 2 \
    --run_name Qwen2.5-VL-7B-FER-COT-SFT-230K \
    --save_steps 20000 \
    --max_grad_norm 5 \
    --save_only_model true
```

#### 3.1.2 å¯åŠ¨è®­ç»ƒ

```bash
cd train_unifer/src/scripts
chmod +x run_sft_fer.sh
bash run_sft_fer.sh
```

#### 3.1.3 ç›‘æ§è®­ç»ƒ

ä½¿ç”¨Weights & Biasesç›‘æ§:

```bash
# ç™»å½•wandb (é¦–æ¬¡ä½¿ç”¨)
wandb login

# åœ¨æµè§ˆå™¨æŸ¥çœ‹: https://wandb.ai/your-username/fer-vlm-training
```

#### 3.1.4 è®­ç»ƒå‚æ•°è¯´æ˜

- `--output_dir`: æ¨¡å‹ä¿å­˜è·¯å¾„
- `--model_name_or_path`: åŸºç¡€æ¨¡å‹è·¯å¾„
- `--dataset_name`: è®­ç»ƒæ•°æ®è·¯å¾„
- `--deepspeed`: DeepSpeedé…ç½®æ–‡ä»¶
- `--per_device_train_batch_size`: æ¯å¼ GPUçš„batch size
- `--gradient_accumulation_steps`: æ¢¯åº¦ç´¯ç§¯æ­¥æ•°
- `--num_train_epochs`: è®­ç»ƒè½®æ•°
- `--bf16`: ä½¿ç”¨bfloat16æ··åˆç²¾åº¦
- `--gradient_checkpointing`: å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹èŠ‚çœæ˜¾å­˜
- `--attn_implementation`: ä½¿ç”¨flash_attention_2åŠ é€Ÿ

#### 3.1.5 é¢„è®¡è®­ç»ƒæ—¶é—´

- **4Ã—A100 (40GB)**: çº¦12-24å°æ—¶ï¼ˆ2 epochsï¼‰
- **4Ã—RTX 3090 (24GB)**: çº¦24-48å°æ—¶

### 3.2 ç¬¬äºŒé˜¶æ®µï¼šå¼ºåŒ–å­¦ä¹  (GRPO)

#### 3.2.1 å‡†å¤‡é…ç½®

ç¼–è¾‘è®­ç»ƒè„šæœ¬ `train_unifer/src/scripts/run_grpo_vllm.sh`:

```bash
#!/bin/bash

cd ./UniFER/train_unifer/src/r1-v

# è°ƒè¯•æ¨¡å¼
export DEBUG_MODE="true"
export LOG_PATH="./debug_log_grpo.txt"

# åˆ›å»ºè¾“å‡ºç›®å½•
OUTPUT_DIR="./log/Qwen2.5-VL-7B-FER-GRPO-VLLM-8GPU"
if [ ! -d "$OUTPUT_DIR" ]; then
 mkdir -p "$OUTPUT_DIR"
fi

# æ¿€æ´»ç¯å¢ƒ
source /miniconda3/bin/activate
conda activate r1-v

# æ³¨æ„: éœ€è¦X+1å¼ GPUï¼ŒXå¼ ç”¨äºè®­ç»ƒï¼Œ1å¼ ç”¨äºvLLMæ¨ç†
# ä¾‹å¦‚: 8å¼ GPUï¼Œä½¿ç”¨7å¼ è®­ç»ƒ + 1å¼ vLLM

CUDA_VISIBLE_DEVICES="0,1,2,3,4,5,6,7" torchrun \
    --nproc_per_node="7" \
    --nnodes="1" \
    --node_rank="0" \
    --master_addr="127.0.0.1" \
    --master_port="12345" \
    src/open_r1/grpo.py \
    --use_vllm true \
    --output_dir './Qwen2.5-VL-7B-FER-GRPO-VLLM-8GPU' \
    --model_name_or_path './UniFER/model/Qwen2.5-VL-7B-FER-COT-SFT-230K' \
    --dataset_name "./UniFER/data/UniFER_RLVR_360K.json" \
    --max_prompt_length 4096 \
    --max_completion_length 1024 \
    --per_device_train_batch_size 1 \
    --gradient_accumulation_steps 4 \
    --learning_rate 1e-6 \
    --lr_scheduler_type "cosine" \
    --weight_decay 0.01 \
    --logging_steps 2 \
    --bf16 true \
    --gradient_checkpointing true \
    --attn_implementation flash_attention_2 \
    --num_train_epochs 1 \
    --run_name "Qwen2.5-VL-7B-FER-GRPO-VLLM-8GPU" \
    --save_steps 1000 \
    --save_total_limit 3 \
    --save_only_model True \
    --report_to wandb \
    --beta 0.04 \
    --min_pixels 3136 \
    --max_pixels 501760 \
    --max_grad_norm 5 \
    --temperature 1.0 \
    --num_generations 8 \
    --vllm_device "cuda:7" \
    --vllm_gpu_memory_utilization 0.8 \
    --deepspeed local_scripts/zero3.json \
    2>&1 | tee "$OUTPUT_DIR/training_log.txt"
```

#### 3.2.2 å¯åŠ¨è®­ç»ƒ

```bash
cd train_unifer/src/scripts
chmod +x run_grpo_vllm.sh
bash run_grpo_vllm.sh
```

#### 3.2.3 GRPOç‰¹æ®Šå‚æ•°è¯´æ˜

- `--use_vllm`: å¯ç”¨vLLMåŠ é€Ÿæ¨ç†
- `--num_generations`: æ¯ä¸ªpromptç”Ÿæˆçš„å€™é€‰æ•°ï¼ˆå»ºè®®4-8ï¼‰
- `--vllm_device`: vLLMä½¿ç”¨çš„GPUï¼ˆé€šå¸¸æ˜¯æœ€åä¸€å¼ ï¼‰
- `--vllm_gpu_memory_utilization`: vLLMæ˜¾å­˜åˆ©ç”¨ç‡
- `--beta`: KLæ•£åº¦æƒ©ç½šç³»æ•°
- `--temperature`: ç”Ÿæˆæ¸©åº¦

#### 3.2.4 é¢„è®¡è®­ç»ƒæ—¶é—´

- **8Ã—A100 (80GB)**: çº¦24-48å°æ—¶ï¼ˆ1 epochï¼‰
- **8Ã—A100 (40GB)**: çº¦36-72å°æ—¶

### 3.3 è®­ç»ƒå¸¸è§é—®é¢˜

#### é—®é¢˜1: æ˜¾å­˜ä¸è¶³ (OOM)

**è§£å†³æ–¹æ¡ˆ**:
1. å‡å°`per_device_train_batch_size`
2. å¢å¤§`gradient_accumulation_steps`
3. å¯ç”¨`gradient_checkpointing`
4. ä½¿ç”¨ZeRO-3æˆ–ZeRO-Offload
5. é™ä½å›¾åƒåˆ†è¾¨ç‡

#### é—®é¢˜2: è®­ç»ƒé€Ÿåº¦æ…¢

**è§£å†³æ–¹æ¡ˆ**:
1. ç¡®è®¤ä½¿ç”¨`flash_attention_2`
2. ä½¿ç”¨`bf16`æ··åˆç²¾åº¦
3. æ£€æŸ¥æ•°æ®åŠ è½½æ˜¯å¦æˆä¸ºç“¶é¢ˆ
4. å¢åŠ GPUæ•°é‡

#### é—®é¢˜3: Lossä¸æ”¶æ•›

**è§£å†³æ–¹æ¡ˆ**:
1. é™ä½å­¦ä¹ ç‡
2. å¢åŠ warmupæ­¥æ•°
3. æ£€æŸ¥æ•°æ®è´¨é‡
4. è°ƒæ•´`max_grad_norm`

---

## ğŸ” å››ã€æ¨¡å‹æ¨ç†

### 4.1 å•æ•°æ®é›†æ¨ç†

ä»¥RAF-DBä¸ºä¾‹ï¼š

#### 4.1.1 ä¿®æ”¹é…ç½®

ç¼–è¾‘ `eval_rafdb/code/infer_unifer.py`ä¸­çš„è·¯å¾„ï¼š

```python
# è¾“å…¥æ–‡ä»¶
input_file = "./UniFER/eval_rafdb/data/rafdb_qa.json"

# è¾“å‡ºæ–‡ä»¶
output_file = "./UniFER/eval_rafdb/results/rafdb_unifer_7b_results.json"

# æ¨¡å‹è·¯å¾„
model_name = "./UniFER/model/UniFER-7B"
```

#### 4.1.2 è¿è¡Œæ¨ç†

```bash
cd eval_rafdb/code
python infer_unifer.py
```

#### 4.1.3 æ¨ç†è¿‡ç¨‹

è„šæœ¬ä¼šï¼š
1. åŠ è½½UniFER-7Bæ¨¡å‹å’Œå¤„ç†å™¨
2. è¯»å–æµ‹è¯•é›†æ•°æ®
3. å¯¹æ¯å¼ å›¾åƒï¼š
   - åŠ è½½å¹¶é¢„å¤„ç†å›¾åƒï¼ˆresizeåˆ°224Ã—224ï¼‰
   - æ„é€ å¤šæ¨¡æ€å¯¹è¯
   - æ¨¡å‹ç”Ÿæˆå“åº”ï¼ˆåŒ…å«æ¨ç†è¿‡ç¨‹å’Œç­”æ¡ˆï¼‰
4. ä¿å­˜æ‰€æœ‰ç»“æœåˆ°JSONæ–‡ä»¶

#### 4.1.4 æŸ¥çœ‹ç»“æœ

```bash
# æŸ¥çœ‹å‰å‡ ä¸ªæ ·æœ¬çš„ç»“æœ
head -100 ./UniFER/eval_rafdb/results/rafdb_unifer_7b_results.json
```

è¾“å‡ºæ ¼å¼ï¼š
```json
{
  "image_path": "/RAF-DB/aligned/test_3068_aligned.jpg",
  "true_label": "neutral",
  "prompt": "...",
  "candidate_labels": [...],
  "model_response": "<think>åˆ†æè¿‡ç¨‹...</think><answer>neutral</answer>"
}
```

### 4.2 æ‰¹é‡æ¨ç†æ‰€æœ‰æ•°æ®é›†

```bash
#!/bin/bash
# ä¾æ¬¡æ¨ç†æ‰€æœ‰æ•°æ®é›†

cd eval_rafdb/code && python infer_unifer.py
cd ../../eval_ferplus/code && python infer_unifer.py
cd ../../eval_affectnet/code && python infer_unifer.py
cd ../../eval_sfew_2.0/code && python infer_unifer.py

echo "æ‰€æœ‰æ•°æ®é›†æ¨ç†å®Œæˆï¼"
```

### 4.3 è‡ªå®šä¹‰æ¨ç†

å¦‚æœè¦åœ¨è‡ªå·±çš„å›¾åƒä¸Šæµ‹è¯•ï¼š

```python
import torch
from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor
from qwen_vl_utils import process_vision_info

# åŠ è½½æ¨¡å‹
model_name = "./UniFER/model/UniFER-7B"
model = Qwen2_5_VLForConditionalGeneration.from_pretrained(
    model_name, 
    torch_dtype=torch.float32,
    device_map="auto"
)
processor = AutoProcessor.from_pretrained(model_name)

# å‡†å¤‡è¾“å…¥
image_path = "your_image.jpg"
prompt = "As an expert in facial expression recognition, which expression is most prominent in this image? Please select your answer from the following candidate labels: surprise, fear, disgust, happiness, sadness, anger, neutral. Provide your detailed reasoning between the <think></think> tags, and then give your final answer between the <answer></answer> tags."

messages = [
    {
        "role": "user",
        "content": [
            {"type": "image", "image": image_path, "resized_height": 224, "resized_width": 224},
            {"type": "text", "text": prompt}
        ]
    }
]

# å¤„ç†è¾“å…¥
text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
image_inputs, _ = process_vision_info(messages)
inputs = processor(text=[text], images=image_inputs, return_tensors="pt").to(model.device)

# ç”Ÿæˆå“åº”
with torch.no_grad():
    generated_ids = model.generate(
        **inputs,
        do_sample=False,
        max_new_tokens=1024,
        use_cache=True
    )

# è§£ç è¾“å‡º
generated_ids_trimmed = generated_ids[0][inputs.input_ids.shape[1]:]
response = processor.decode(generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False)

print("æ¨¡å‹å“åº”:", response)
```

---

## ğŸ“Š äº”ã€æ¨¡å‹è¯„ä¼°

### 5.1 å•æ•°æ®é›†è¯„ä¼°

#### 5.1.1 è¿è¡Œè¯„ä¼°

```bash
cd eval_rafdb/code
python eval_unifer.py
```

#### 5.1.2 è¯„ä¼°è¾“å‡º

ç»ˆç«¯è¾“å‡ºç¤ºä¾‹ï¼š
```
æ­£åœ¨åŠ è½½æ¨ç†ç»“æœ: ./UniFER/eval_rafdb/results/rafdb_unifer_7b_results.json
æ¨ç†ç»“æœåŠ è½½å®Œæˆï¼Œå…± 3068 ä¸ªæ ·æœ¬

æ€»æ ·æœ¬æ•°: 3068
é”™è¯¯æ ·æœ¬: 0
æ— æ³•è¯†åˆ«çš„é¢„æµ‹: 5
æœ‰æ•ˆé¢„æµ‹: 3068

===== æ•´ä½“æ€§èƒ½æŒ‡æ ‡ =====
å‡†ç¡®ç‡ (Accuracy): 0.9234
ç²¾ç¡®ç‡ (Precision, macro): 0.9156
å¬å›ç‡ (Recall, macro): 0.9187
F1åˆ†æ•° (F1-Score, macro): 0.9171

===== æ··æ·†çŸ©é˜µ =====
...

===== å„ç±»åˆ«æ€§èƒ½æŒ‡æ ‡ =====
ç±»åˆ«          ç²¾ç¡®ç‡      å¬å›ç‡      F1åˆ†æ•°      æ ·æœ¬æ•°     
surprise     0.9456     0.9512     0.9484     492       
happiness    0.9789     0.9823     0.9806     1185      
...

è¯„ä¼°æŒ‡æ ‡å·²ä¿å­˜è‡³: ./UniFER/eval_rafdb/results/rafdb_unifer_7b_metrics.json
```

#### 5.1.3 æŸ¥çœ‹è¯¦ç»†ç»“æœ

```bash
# æŸ¥çœ‹ä¿å­˜çš„è¯„ä¼°æŒ‡æ ‡
cat ./UniFER/eval_rafdb/results/rafdb_unifer_7b_metrics.json
```

### 5.2 æ€»ä½“è¯„ä¼°

æ±‡æ€»æ‰€æœ‰æ•°æ®é›†çš„æ€§èƒ½ï¼š

```bash
cd eval_total/code
python eval_unifer.py
```

è¿™ä¼šï¼š
1. åŠ è½½æ‰€æœ‰4ä¸ªæ•°æ®é›†çš„æ¨ç†ç»“æœ
2. ç»Ÿä¸€æ ‡ç­¾æ ¼å¼
3. è®¡ç®—è·¨æ•°æ®é›†çš„æ•´ä½“æŒ‡æ ‡
4. ç”Ÿæˆç»¼åˆæŠ¥å‘Š

### 5.3 ç»“æœåˆ†æ

#### 5.3.1 æ··æ·†çŸ©é˜µåˆ†æ

æŸ¥çœ‹å“ªäº›ç±»åˆ«å®¹æ˜“æ··æ·†ï¼š
- å¯¹è§’çº¿å€¼é«˜è¡¨ç¤ºè¯¥ç±»åˆ«è¯†åˆ«å‡†ç¡®
- éå¯¹è§’çº¿å€¼é«˜è¡¨ç¤ºå¸¸è§æ··æ·†

#### 5.3.2 æ¯ç±»åˆ«æ€§èƒ½

å…³æ³¨ï¼š
- F1åˆ†æ•°ä½çš„ç±»åˆ«ï¼ˆéœ€è¦æ”¹è¿›ï¼‰
- æ ·æœ¬æ•°å°‘çš„ç±»åˆ«ï¼ˆå¯èƒ½éœ€è¦æ•°æ®å¢å¼ºï¼‰

#### 5.3.3 é”™è¯¯åˆ†æ

æŸ¥çœ‹é¢„æµ‹é”™è¯¯çš„æ ·æœ¬ï¼š
```python
import json

# åŠ è½½ç»“æœ
with open("./UniFER/eval_rafdb/results/rafdb_unifer_7b_results.json") as f:
    results = json.load(f)

# æ‰¾å‡ºé”™è¯¯æ ·æœ¬
errors = []
for item in results:
    if "model_response" in item:
        # æå–é¢„æµ‹æ ‡ç­¾ï¼ˆç®€åŒ–ç‰ˆï¼‰
        if item["true_label"] not in item["model_response"]:
            errors.append({
                "image": item["image_path"],
                "true": item["true_label"],
                "response": item["model_response"]
            })

print(f"é”™è¯¯æ ·æœ¬æ•°: {len(errors)}")
# æŸ¥çœ‹å‰å‡ ä¸ªé”™è¯¯
for i, err in enumerate(errors[:5]):
    print(f"\né”™è¯¯ {i+1}:")
    print(f"å›¾åƒ: {err['image']}")
    print(f"çœŸå®æ ‡ç­¾: {err['true']}")
    print(f"æ¨¡å‹å“åº”: {err['response'][:200]}...")
```

---

## ğŸ› ï¸ å…­ã€è¿›é˜¶ä½¿ç”¨

### 6.1 è°ƒæ•´ç”Ÿæˆå‚æ•°

åœ¨`infer_unifer.py`ä¸­ä¿®æ”¹ç”Ÿæˆå‚æ•°ï¼š

```python
generated_ids = model.generate(
    **inputs,
    do_sample=True,           # å¯ç”¨é‡‡æ ·ï¼ˆæ›´å¤šæ ·åŒ–ï¼‰
    temperature=0.7,          # æ¸©åº¦ï¼ˆè¶Šé«˜è¶Šéšæœºï¼‰
    top_p=0.9,                # nucleus sampling
    top_k=50,                 # top-k sampling
    max_new_tokens=2048,      # å¢åŠ æœ€å¤§é•¿åº¦
    use_cache=True,
    repetition_penalty=1.1,   # æƒ©ç½šé‡å¤
)
```

### 6.2 æ‰¹é‡æ¨ç†åŠ é€Ÿ

ä½¿ç”¨DataLoaderæ‰¹é‡å¤„ç†ï¼š

```python
from torch.utils.data import Dataset, DataLoader

class FERDataset(Dataset):
    def __init__(self, data, processor):
        self.data = data
        self.processor = processor
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        item = self.data[idx]
        # å¤„ç†å•ä¸ªæ ·æœ¬
        ...
        return processed_item

# åˆ›å»ºDataLoader
dataset = FERDataset(data, processor)
dataloader = DataLoader(dataset, batch_size=4, num_workers=4)

# æ‰¹é‡æ¨ç†
for batch in dataloader:
    with torch.no_grad():
        outputs = model.generate(**batch, ...)
```

### 6.3 ä½¿ç”¨vLLMåŠ é€Ÿæ¨ç†

å¯¹äºå¤§è§„æ¨¡æ¨ç†ï¼Œä½¿ç”¨vLLMï¼š

```python
from vllm import LLM, SamplingParams

# åˆå§‹åŒ–vLLM
llm = LLM(
    model="./UniFER/model/UniFER-7B",
    tensor_parallel_size=1,
    gpu_memory_utilization=0.9
)

# è®¾ç½®é‡‡æ ·å‚æ•°
sampling_params = SamplingParams(
    temperature=0.0,
    max_tokens=1024,
    stop=["</answer>"]
)

# æ‰¹é‡æ¨ç†
prompts = [...]  # å‡†å¤‡å¥½çš„promptsåˆ—è¡¨
outputs = llm.generate(prompts, sampling_params)

for output in outputs:
    print(output.outputs[0].text)
```

### 6.4 å¾®è°ƒåˆ°æ–°æ•°æ®é›†

å¦‚æœè¦åœ¨è‡ªå·±çš„æ•°æ®é›†ä¸Šå¾®è°ƒï¼š

1. **å‡†å¤‡æ•°æ®**ï¼šè½¬æ¢ä¸ºUniFERæ ¼å¼
```json
{
  "image_path": "your/image/path.jpg",
  "question": "è¡¨æƒ…è¯†åˆ«æç¤ºè¯",
  "response": "<think>æ¨ç†è¿‡ç¨‹</think><answer>æ ‡ç­¾</answer>"
}
```

2. **ä¿®æ”¹è®­ç»ƒè„šæœ¬**ï¼š
   - æ›´æ–°`--dataset_name`è·¯å¾„
   - è°ƒæ•´è®­ç»ƒè½®æ•°å’Œå­¦ä¹ ç‡

3. **å¯åŠ¨è®­ç»ƒ**ï¼š
```bash
bash run_sft_fer.sh
```

---

## ğŸ“ˆ ä¸ƒã€æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 7.1 æ¨ç†ä¼˜åŒ–

1. **ä½¿ç”¨é‡åŒ–æ¨¡å‹**
   ```python
   from transformers import BitsAndBytesConfig
   
   bnb_config = BitsAndBytesConfig(
       load_in_4bit=True,
       bnb_4bit_compute_dtype=torch.bfloat16
   )
   
   model = Qwen2_5_VLForConditionalGeneration.from_pretrained(
       model_name,
       quantization_config=bnb_config,
       device_map="auto"
   )
   ```

2. **ä½¿ç”¨TensorRT**
   - ç¼–è¯‘æ¨¡å‹ä¸ºTensorRTå¼•æ“
   - å¤§å¹…æå‡æ¨ç†é€Ÿåº¦

3. **æ‰¹é‡å¤„ç†**
   - å¢å¤§batch sizeï¼ˆæ˜¾å­˜å…è®¸çš„æƒ…å†µä¸‹ï¼‰
   - ä½¿ç”¨DataLoaderå¹¶è¡ŒåŠ è½½

### 7.2 è®­ç»ƒä¼˜åŒ–

1. **æ¢¯åº¦ç´¯ç§¯**
   - å‡å°å®é™…batch size
   - å¢å¤§ç´¯ç§¯æ­¥æ•°
   - ç­‰æ•ˆæ›´å¤§batch size

2. **æ··åˆç²¾åº¦è®­ç»ƒ**
   - ä½¿ç”¨bf16æˆ–fp16
   - èŠ‚çœæ˜¾å­˜ï¼ŒåŠ é€Ÿè®¡ç®—

3. **åˆ†å¸ƒå¼è®­ç»ƒ**
   - å¤šå¡å¹¶è¡Œ
   - DeepSpeed ZeROä¼˜åŒ–

---

## ğŸ› å…«ã€æ•…éšœæ’æŸ¥

### 8.1 å¸¸è§é”™è¯¯

#### é”™è¯¯1: CUDA out of memory

**åŸå› **: æ˜¾å­˜ä¸è¶³

**è§£å†³**:
```bash
# å‡å°batch size
--per_device_train_batch_size 1

# å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
--gradient_checkpointing true

# ä½¿ç”¨DeepSpeed ZeRO-3
--deepspeed local_scripts/zero3.json
```

#### é”™è¯¯2: ImportError: No module named 'xxx'

**åŸå› **: ç¼ºå°‘ä¾èµ–åŒ…

**è§£å†³**:
```bash
pip install xxx
```

#### é”™è¯¯3: RuntimeError: NCCL error

**åŸå› **: åˆ†å¸ƒå¼é€šä¿¡é—®é¢˜

**è§£å†³**:
```bash
# æ£€æŸ¥NCCLç‰ˆæœ¬
python -c "import torch; print(torch.cuda.nccl.version())"

# è®¾ç½®ç¯å¢ƒå˜é‡
export NCCL_DEBUG=INFO
export NCCL_IB_DISABLE=1
```

### 8.2 æ—¥å¿—åˆ†æ

æŸ¥çœ‹è®­ç»ƒæ—¥å¿—ï¼š
```bash
# å®æ—¶æŸ¥çœ‹
tail -f ./log/Qwen2.5-VL-7B-FER-GRPO-VLLM-8GPU/training_log.txt

# æœç´¢é”™è¯¯
grep -i "error" ./log/*/training_log.txt

# æŸ¥çœ‹lossæ›²çº¿
grep "loss" ./log/*/training_log.txt | tail -20
```

---

## ğŸ“ ä¹ã€æŠ€æœ¯æ”¯æŒ

### è·å–å¸®åŠ©

1. **GitHub Issues**: https://github.com/zfkarl/UniFER/issues
2. **é‚®ä»¶è”ç³»**: fzhang@link.cuhk.edu.hk
3. **å‚è€ƒæ–‡æ¡£**:
   - [UniFERè®ºæ–‡](https://arxiv.org/pdf/2511.00389)
   - [Qwen2.5-VLæ–‡æ¡£](https://github.com/QwenLM/Qwen2-VL)
   - [DeepSpeedæ–‡æ¡£](https://www.deepspeed.ai/)

### è´¡çŒ®ä»£ç 

æ¬¢è¿æäº¤Pull Requestï¼

---

## ğŸ“„ åã€è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ªç›¸å…³å¼€æºè®¸å¯è¯ï¼Œè¯¦è§LICENSEæ–‡ä»¶ã€‚

---

**ç¥ä½¿ç”¨æ„‰å¿«ï¼å¦‚æœ‰é—®é¢˜ï¼Œæ¬¢è¿éšæ—¶è”ç³»ã€‚**
