# UniFER 项目完整流程文档

## 📋 项目概述

### 项目背景
UniFER (Unified Facial Expression Recognition) 是一个基于多模态大语言模型(MLLM)的统一面部表情识别系统。该项目重新思考了在多模态大语言模型时代的面部表情识别任务，提出了全新的训练范式和评估基准。

### 核心创新点
1. **FERBench基准**: 将20个SOTA的MLLMs在4个FER数据集上进行系统性评估
2. **UniFER-CoT-230K**: 高质量的冷启动初始化数据集，包含思维链(Chain-of-Thought)推理
3. **UniFER-RLVR-360K**: 用于可验证奖励强化学习(RLVR)的数据集
4. **UniFER-7B模型**: 统一且可解释的FER基础模型

### 技术栈
- **基础模型**: Qwen2.5-VL-7B-Instruct
- **训练框架**: PyTorch + DeepSpeed + TRL
- **强化学习**: GRPO (Group Relative Policy Optimization) with vLLM
- **评估数据集**: RAF-DB, FERPlus, AffectNet, SFEW 2.0

---

## 🏗️ 项目结构

```
UniFER/
├── eval_affectnet/          # AffectNet数据集评估
│   ├── code/
│   │   ├── infer_unifer.py  # 推理脚本
│   │   └── eval_unifer.py   # 评估脚本
│   └── data/
│       └── affectnet_qa.json # 测试集问答数据
├── eval_ferplus/            # FERPlus数据集评估
├── eval_rafdb/              # RAF-DB数据集评估
├── eval_sfew_2.0/           # SFEW 2.0数据集评估
├── eval_total/              # 总体评估
│   └── code/
│       └── eval_unifer.py   # 汇总所有数据集的评估
├── train_unifer/            # 模型训练
│   └── src/
│       ├── r1-v/
│       │   └── src/open_r1/
│       │       ├── sft_fer.py  # 监督微调脚本
│       │       ├── grpo.py     # GRPO强化学习脚本
│       │       └── trainer/    # 自定义训练器
│       └── scripts/
│           ├── run_sft_fer.sh   # SFT训练启动脚本
│           └── run_grpo_vllm.sh # GRPO训练启动脚本
├── data/                    # 训练数据
│   ├── UniFER_CoT_230K.json    # 冷启动SFT数据集
│   └── UniFER_RLVR_360K.json   # 强化学习数据集
├── model/                   # 模型存储
│   ├── Qwen2.5-VL-7B-Instruct/           # 基础模型
│   ├── Qwen2.5-VL-7B-FER-COT-SFT-230K/   # SFT后的模型
│   └── UniFER-7B/                         # 最终模型
└── readme.md                # 项目说明文档
```

---

## 🔄 完整工作流程

### 阶段一：数据准备

#### 1.1 下载原始数据集
需要从官方网站下载以下4个数据集的图像：
- **RAF-DB**: 真实场景的面部表情数据库
- **FERPlus**: 基于FER2013改进的数据集
- **AffectNet**: 大规模表情数据集
- **SFEW 2.0**: 静态面部表情数据集

#### 1.2 数据集转换为VQA格式
每个数据集被转换为视觉问答(VQA)格式，包含：
```json
{
  "image_path": "图像路径",
  "true_label": "真实标签",
  "prompt": "提示词",
  "candidate_labels": ["标签列表"]
}
```

#### 1.3 训练数据准备
- **UniFER-CoT-230K**: 包含思维链推理的问答对
- **UniFER-RLVR-360K**: 用于强化学习的多样化样本

---

### 阶段二：模型训练

#### 2.1 第一阶段：冷启动监督微调 (SFT)

**目标**: 让基础模型学会面部表情识别和思维链推理

**输入数据**: UniFER-CoT-230K.json

**训练配置**:
```bash
- 基础模型: Qwen2.5-VL-7B-Instruct
- 训练方法: 监督微调 (Supervised Fine-Tuning)
- 优化器: DeepSpeed ZeRO-2
- GPU配置: 4卡训练
- Batch Size: 1 per device × 4 gradient accumulation = 4
- 训练轮数: 2 epochs
- 学习率调度: Cosine
```

**数据格式**:
```python
{
  "image_path": "图像路径",
  "question": "用户提问",
  "response": "<think>推理过程</think><answer>答案</answer>"
}
```

**关键代码**: `train_unifer/src/r1-v/src/open_r1/sft_fer.py`

**执行命令**:
```bash
cd train_unifer/src/scripts
bash run_sft_fer.sh
```

**输出**: `Qwen2.5-VL-7B-FER-COT-SFT-230K` 模型检查点

#### 2.2 第二阶段：强化学习 (GRPO with RLVR)

**目标**: 通过强化学习进一步提升模型的推理能力和准确性

**输入数据**: UniFER-RLVR-360K.json

**训练配置**:
```bash
- 初始模型: Qwen2.5-VL-7B-FER-COT-SFT-230K
- 训练方法: GRPO (Group Relative Policy Optimization)
- 推理引擎: vLLM (加速生成)
- GPU配置: 8卡 (7卡训练 + 1卡vLLM推理)
- 每批次生成: 8个候选响应
- 奖励函数: accuracy + format
- 训练轮数: 1 epoch
```

**奖励函数**:
1. **Accuracy Reward**: 检查答案是否正确
2. **Format Reward**: 检查是否符合`<think>...</think><answer>...</answer>`格式

**关键代码**: 
- `train_unifer/src/r1-v/src/open_r1/grpo.py`
- `train_unifer/src/r1-v/src/open_r1/trainer/vllm_grpo_trainer_modified.py`

**执行命令**:
```bash
cd train_unifer/src/scripts
bash run_grpo_vllm.sh
```

**输出**: `UniFER-7B` 最终模型

---

### 阶段三：模型评估

#### 3.1 单数据集推理

对每个数据集执行推理，生成模型响应：

**RAF-DB示例**:
```bash
cd eval_rafdb/code
python infer_unifer.py
```

**执行流程**:
1. 加载UniFER-7B模型
2. 读取测试集JSON (`rafdb_qa.json`)
3. 对每张图像进行推理：
   - 将图像缩放到224×224
   - 构造多模态对话格式
   - 模型生成响应（包含推理过程和答案）
4. 保存结果到JSON文件

**输出**: `rafdb_unifer_7b_results.json` 包含每个样本的模型响应

#### 3.2 单数据集评估

计算性能指标：

```bash
cd eval_rafdb/code
python eval_unifer.py
```

**执行流程**:
1. 加载推理结果JSON
2. 从模型响应中提取预测标签：
   - 优先从`<answer>`标签提取
   - 使用正则表达式匹配
   - 同义词映射
3. 计算指标：
   - 准确率 (Accuracy)
   - 精确率 (Precision)
   - 召回率 (Recall)
   - F1分数
   - 混淆矩阵
   - 每类别详细指标
4. 保存评估结果

**输出**: `rafdb_unifer_7b_metrics.json`

#### 3.3 总体评估

汇总所有数据集的性能：

```bash
cd eval_total/code
python eval_unifer.py
```

**执行流程**:
1. 加载所有4个数据集的推理结果
2. 统一标签格式（如angry→anger）
3. 计算跨数据集的总体指标
4. 生成综合评估报告

---

## 🔬 技术细节

### 多模态处理流程

1. **图像处理**:
   - 图像resize到224×224像素
   - 使用Qwen2.5-VL的image processor预处理
   - 转换为模型可接受的tensor格式

2. **文本处理**:
   - 应用对话模板(chat template)
   - Tokenization
   - 与视觉token融合

3. **推理生成**:
   - 贪婪解码 (do_sample=False)
   - 最大生成长度: 1024 tokens
   - 使用KV缓存加速

### 思维链推理格式

UniFER使用特殊的XML标签格式：

```xml
<think>
面部分析：
- 眉毛：微微上扬
- 眼睛：睁大且有光泽
- 嘴巴：嘴角上扬，露出牙齿
综合判断：这些特征表明一种积极、愉快的情绪状态。
</think>
<answer>happiness</answer>
```

这种格式的优势：
- **可解释性**: 展示推理过程
- **可验证性**: 便于强化学习验证
- **结构化**: 易于程序化解析

### GRPO强化学习机制

**工作原理**:
1. 对每个prompt生成N个候选响应（N=8）
2. 计算每个响应的奖励分数
3. 使用相对奖励优化策略
4. 更新模型参数

**奖励计算**:
```python
total_reward = accuracy_reward + format_reward
```

**优势**:
- 无需单独的奖励模型
- 组内相对优化，更稳定
- 结合vLLM加速生成

---

## 📊 评估指标说明

### 准确率 (Accuracy)
```
Accuracy = 正确预测数 / 总样本数
```

### 精确率 (Precision)
```
Precision = TP / (TP + FP)
```
表示预测为正类的样本中真正为正类的比例

### 召回率 (Recall)
```
Recall = TP / (TP + FN)
```
表示真正为正类的样本中被正确预测的比例

### F1分数 (F1-Score)
```
F1 = 2 × (Precision × Recall) / (Precision + Recall)
```
精确率和召回率的调和平均值

### 宏平均 (Macro Average)
对所有类别的指标取平均值，不考虑类别不平衡

### 混淆矩阵 (Confusion Matrix)
行表示真实标签，列表示预测标签，对角线为正确预测

---

## 🎯 快速开始指南

### 环境配置
```bash
# 创建conda环境
conda create -n r1-v python=3.11
conda activate r1-v

# 安装依赖 (参考R1-V官方文档)
# 需要安装 PyTorch, transformers, trl, deepspeed, vllm等
```

### 仅推理评估
```bash
# 1. 下载UniFER-7B模型
# 从 https://huggingface.co/Karl28/UniFER-7B 下载

# 2. 准备数据集图像

# 3. 运行推理
cd eval_rafdb/code
python infer_unifer.py

# 4. 计算指标
python eval_unifer.py
```

### 完整训练流程
```bash
# 1. 下载数据集
# 下载 UniFER-CoT-230K.json 和 UniFER-RLVR-360K.json

# 2. 第一阶段训练 (SFT)
cd train_unifer/src/scripts
bash run_sft_fer.sh

# 3. 第二阶段训练 (GRPO)
bash run_grpo_vllm.sh

# 4. 评估所有数据集
cd ../../eval_rafdb/code && python infer_unifer.py && python eval_unifer.py
cd ../../eval_ferplus/code && python infer_unifer.py && python eval_unifer.py
cd ../../eval_affectnet/code && python infer_unifer.py && python eval_unifer.py
cd ../../eval_sfew_2.0/code && python infer_unifer.py && python eval_unifer.py
cd ../../eval_total/code && python eval_unifer.py
```

---

## 🐛 常见问题

### 1. 显存不足
- 减少batch size
- 使用梯度累积
- 启用ZeRO-3或ZeRO-Offload
- 使用bfloat16替代float32

### 2. 训练速度慢
- 使用flash_attention_2
- 启用梯度检查点
- 增加GPU数量
- 使用vLLM加速推理

### 3. 评估时标签提取失败
- 检查同义词映射表
- 调整正则表达式
- 查看模型原始输出

---

## 📚 参考资料

- **论文**: [Rethinking Facial Expression Recognition in the Era of Multimodal Large Language Models](https://arxiv.org/pdf/2511.00389)
- **模型**: https://huggingface.co/Karl28/UniFER-7B
- **数据集**: https://huggingface.co/datasets/Karl28/UniFER
- **基础框架**: https://github.com/StarsfieldAI/R1-V

---

## 📧 联系方式

如有问题或建议，请联系: `fzhang@link.cuhk.edu.hk`
